---
title: Fibers for Games
layout: blogpost
author: James Keats
selectedurl: Blog
tags: code architecture multithreading
description: Have you ever felt that normal multithreading isn't complicated enough?
---

Using fibers for game development is something that, like many other systems programmers, I've been fascinated by ever since seeing Naughty Dog's 2015 GDC talk: [Parallelizing the Naughty Dog Engine Using Fibers](https://archive.org/details/GDC2015Gyrling_201508). I would recommend that anyone interested in having as many tools in their multithreading belt as possible give it a watch.

# What Are Fibers?

I'll provide a **very** brief overview of what fibers actually are here, but for a more in-depth dive I recommend checking out the links I have below. 

Fibers (sometimes referred to as green threads, user-space threads, virtual threads, and a litany of other names) are threads of execution which are "scheduled" in user space. Via user-space calls, they can be suspended (or "yielded") and resumed manually. The article [Fibers, Oh My](https://graphitemaster.github.io/fibers/) by Dale Weiler contains a great explanation of preemptive vs cooperatively scheduled execution, although it contains a few points which I consider to be mistakes or errors and items which are explained in a very prescriptivist way which in actuality I think are use-case dependent. I'll address some of that below. However, the discussion on scheduling is spot-on, and I'll quote it here:

> Most people familiar with threads know that you don’t have to **yield** to other threads to allow them to run. This is because most operating systems (OS) schedule threads **preemptively**. [...] This is possible because the OS will decide at [calls to IO, sleeps, waits, and interrupts] to save all the relevant state of that thread then resume some other thread, the idea being that when this thread can run again, the OS can reinstate that thread and continue executing it like nothing ever happened
>
> [...]
>
> This idea of fibers yielding to each other is what is known as cooperative scheduling. Fibers effectively move the idea of context switching from kernel-space to user-space and then make those switches a fundamental part of computation, that is, they’re a deliberate and explicitly done thing, by the fibers themselves.
> 
> - [Fibers, Oh My!](https://graphitemaster.github.io/fibers/) by Dale Weiler

Different people seem to have different ideas about why fibers are useful. Dale Weiler stresses the ability for yielding between fibers to potentially be much faster than an OS context switch. Conversely, Naughty Dog actively downplays the performance, saying that it was not at all their main focus but that instead their goal was usability for gameplay programmers; ultimately their goal was performance, but the "point" was to easily convert systems to small tasks/jobs, not have the fastest context switches.

The main thing that intrigues me about fibers is not just the scheduling capacity in and of itself. I have written thread pools before and while there were definitely pain points involved with scheduling, I very rarely ran into situations where I felt I needed cooperative scheduling. The OS typically does a fine enough job when given sleeps and event waits. Instead, what is most interesting to me is the ability to easily break up the work done by large, heavy systems which takes more than one frame and needs to be amortized over multiple frames. Things that come to mind here are data parsing, navigation generation, decompression, etc. For these systems, there are typically two options: push the whole monolithic task onto another thread, or totally restructure your code to manually turn it into a state machine that can be left and resumed. The former can starve your task system of worker threads needed for frame-critical work and the latter is a real pain that makes the code more difficult to understand, more complex, and more fragile. Fibers can solve this problem by allowing you to simply `yield` your large task partway through, allowing other work to be completed, effectively giving you a "state machine" for free, using (call) stack to save your state.

It's worth noting there are different "topographies" over which fibers can be implemented. The simplest to implement and understand is `N:1`, whereby you have N fibers running on 1 hardware thread. This gets you some of the benefits such as being able to yield and resume major systems, but lacks actual parallelism. This allows you to write a form of task-based code without needing to worry about synchronization or race conditions, but you're not actually taking advantage of modern processing power. What we're primarily interested in is an `M:N` system, where many threads run many fibers. This means we now once again need to care about resource access and race conditions, but we get the benefit of fibers as well.

# Fibers vs Thread Pools/Task Systems/Job Managers/etc

In games, to limit context switching and poor time-slicing it is common to try to match the number of threads launched by your application to the number of physical threads available on the machine. In a fairly typical scenario, this could mean you have a game thread, a render thread, and then (Cores - 2) worker threads in your thread pool. This pool is then useable for any "asynchronous" work that you wish to perform. Some common use cases that come to mind are physics simulation and bulk-raycast query processing, animation pose calculations, certain rendering work such as draw call recording, and more (these are all present in Unreal Engine 4, for example). Typically these systems will have some way to track dependencies between tasks, or at the very least allow the task code to itself launch other tasks.

# How Are Fibers Implemented?

In Naughty Dog's talk, there are a few different components of their engine that they touch on: the actual fiber resource management and scheduling system itself (very briefly), synchronization between fibers which they do exclusively via counters and "wait for value" semantics, and then a relatively in-depth look into how they manage the concept of "frames" within this system primarily for resource management, allowing them to run rendering work for one frame simultaneously with game logic for another frame.

The part that they are probably the most sparse about is the actual management of the fibers. I think in part this is because they are using Sony's (proprietary) API for most of the low-level work. This gets skipped over because it isn't really important to the point of the talk, it's covered by NDA, and it's irrelevant for anyone developing for other platforms. Of course, if you go digging, you will find that APIs for fibers exist on other platforms as well, although they don't necessarily allow you to do all the things that are mentioned in this talk. For example, the Windows API has `::CreateFiber` and `::SwitchToFiber`. These are functions which could be used to create a similar system, but we would be unable to use our own memory management for stack space. Depending on your use case, it also spends cycles modifying and saving state which you might not care about. (Of course, the Windows API also knows Windows best... if you fail to modify or save some of the state that they do, you may find random system calls crash or behave unexpectedly).

# Warning: Overly Cautious Warnings

When reading about fibers, there are a great many warnings and cautionary tales I encountered which I felt were overly prescriptivist, but perhaps someone else has understood something I've missed. Here are a few things:

### Warnings everywhere about how long-running work stops the progress of other fibers

### Warnings everywhere to avoid OS sync primitives and IO

